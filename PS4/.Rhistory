top_n(n = 5, wt = retweet_count) %>%
arrange(desc(retweet_count)) %>%
select(text)))
most_retweeted <- original_tweets %>%
# top 5 most retweeted
top_n(n = 5, wt = retweet_count) %>%
arrange(desc(retweet_count)) %>%
select(text)
original_tweets <- tweets %>%
# remove retweets
filter(is_retweet == FALSE)
most_popular <- original_tweets %>%
# top 5 most popular
top_n(n = 5, wt = favorite_count) %>%
arrange(desc(favorite_count)) %>%
select(text)
most_retweeted <- original_tweets %>%
# top 5 most retweeted
top_n(n = 5, wt = retweet_count) %>%
arrange(desc(retweet_count)) %>%
select(text)
lapply(unlist(most_popular), function(x) print(x))
lapply(most_popular, function(x) print(x))
original_tweets <- tweets %>%
# remove retweets
filter(is_retweet == FALSE)
most_popular <- original_tweets %>%
# top 5 most popular
top_n(n = 5, wt = favorite_count) %>%
arrange(desc(favorite_count)) %>%
select(text)
most_retweeted <- original_tweets %>%
# top 5 most retweeted
top_n(n = 5, wt = retweet_count) %>%
arrange(desc(retweet_count)) %>%
select(text)
lapply(most_popular, function(x) print(x))
most_popular
print(most_popular)
print(unlist(most_popular))
unlist(most_popular)
most_popular
for (i in 1:5){
print(most_popular[i])
}
for (i in 1:3){
print(most_popular[i])
}
# lapply(most_popular, function(x) print(x))
most_popular <- unlist(most_popular)
for (i in 1:3){
print(most_popular[i])
}
print(most_popular)
library(tm)
Corpus <- VCorpus(original_tweets$text)
Corpus <- VCorpus(list(original_tweets$text))
docs <- c("This is a text.", "This another one.")
VCorpus(VectorSource(docs))
Corpus <- VCorpus(VectorSource(original_tweets$text))
Corpus
inspect(Corpus[[2]])
inspect(Corpus[[1]])
lapply(Corpus[1:2], as.character)
# remove whitespace
tm_map(Corpus, stripWhitespace)
# remove whitespace
Corpus <- tm_map(Corpus, stripWhitespace)
inspect(Corpus[[1]])
Corpus <- VCorpus(VectorSource(original_tweets$text))
inspect(Corpus[[1]])
# remove whitespace
Corpus <- tm_map(Corpus, stripWhitespace)
inspect(Corpus[[1]])
# convert to lower case
Corpus <- tm_map(Corpus, content_transformer(tolower))
inspect(Corpus[[1]])
# remove stop words
Corpus <- tm_map(Corpus, removeWords, stopwords("english"))
inspect(Corpus[[1]])
# remove numbers and punctuation
tm_map(Corpus, removeNumbers)
# remove numbers and punctuation
Corpus <- tm_map(Corpus, removeNumbers)
inspect(Corpus[[1]])
inspect(Corpus[[5]])
Corpus <- VCorpus(VectorSource(original_tweets$text))
inspect(Corpus[[5]])
# remove whitespace
Corpus <- tm_map(Corpus, stripWhitespace)
# remove numbers
Corpus <- tm_map(Corpus, removeNumbers)
# remove punctuation
Corpus <- tm_map(Corpus, removePunctuation)
# convert to lower case
Corpus <- tm_map(Corpus, content_transformer(tolower))
# remove stop words
Corpus <- tm_map(Corpus, removeWords, stopwords("english"))
inspect(Corpus[[5]])
Corpus
termFreq(Corpus)
termFreq(Corpus[1])
Corpus
TermDocumentMatrix(Corpus)
tdm <- TermDocumentMatrix(Corpus)
tdm <- TermDocumentMatrix(Corpus)
findFreqTerms(tdm, 2, 3)
# remove punctuation
Corpus <- tm_map(Corpus, removePunctuation(ucp = TRUE))
# remove punctuation
Corpus <- tm_map(Corpus, removePunctuation(Corpus, ucp = TRUE))
# remove punctuation
Corpus <- tm_map(Corpus, removePunctuation(ucp = TRUE))
# remove punctuation
Corpus <- tm_map(Corpus, removePunctuation, ucp = TRUE)
Corpus <- VCorpus(VectorSource(original_tweets$text))
inspect(Corpus[[5]])
# remove whitespace
Corpus <- tm_map(Corpus, stripWhitespace)
# remove numbers
Corpus <- tm_map(Corpus, removeNumbers)
# remove punctuation
Corpus <- tm_map(Corpus, removePunctuation, ucp = TRUE)
# convert to lower case
Corpus <- tm_map(Corpus, content_transformer(tolower))
# remove stop words
Corpus <- tm_map(Corpus, removeWords, stopwords("english"))
inspect(Corpus[[5]])
findMostFreqTerms(tdm, n = 50L)
tdm
findFreqTerms(tdm, 3, Inf)
findFreqTerms(tdm, 1000, Inf)
findMostFreqTerms(tdm, n = 1)
Corpus <- VCorpus(VectorSource(original_tweets$text))
inspect(Corpus[[5]])
# Corpus <- tm_map(Corpus, stripWhitespace)
# Corpus <- tm_map(Corpus, removeNumbers)
# Corpus <- tm_map(Corpus, removePunctuation, ucp = TRUE)
Corpus <- Corpus %>%
# remove numbers
tm_map(removeNumbers) %>%
# remove punctuation
tm_map(removePunctuation, ucp = TRUE) %>%
# remove whitespace
tm_map(stripWhitespace)
# convert to lower case
Corpus <- tm_map(Corpus, content_transformer(tolower))
# remove stop words
Corpus <- tm_map(Corpus, removeWords, stopwords("english"))
inspect(Corpus[[5]])
tdm <- TermDocumentMatrix(Corpus)
matrix <- as.matrix(tdm)
tweets_words <-  original_tweets %>%
select(text) %>%
unnest_tokens(word, text)
# tdm <- TermDocumentMatrix(Corpus)
# matrix <- as.matrix(tdm)
# words <- sort(rowSums(matrix),decreasing=TRUE)
# df <- data.frame(word = names(words),freq=words)
library(tidytext)
library(tidytext)
tweets_words <-  original_tweets %>%
select(text) %>%
unnest_tokens(word, text)
words <- tweets_words %>% count(word, sort=TRUE)
View(words)
tdm <- TermDocumentMatrix(Corpus)
matrix <- as.matrix(tdm)
knitr::opts_chunk$set(echo = TRUE)
options(width = 80)
# Change eval=FALSE in the code block. Install packages as appropriate.
library(fivethirtyeight)
library(tidyverse)
library(dplyr)
library(readr)
library(tidytext)
library(tm)
library(lubridate)
library(wordcloud)
# URL to the data that you've used.
# url <- 'https://jmontgomery.github.io/PDS/Datasets/president_primary_polls_feb2020.csv'
polls <- read_csv("president_primary_polls_feb2020.csv")
Endorsements <- endorsements_2020 # from the fiverthirtyeight package
# rename() to change variable name
Endorsements <- rename(Endorsements, candidate_name = endorsee)
# check to see whether the change took place
names(Endorsements)
Endorsements <- as_tibble(Endorsements)
# check if the class includes tibble
class(Endorsements)
# create a new dataset to store the changes
polls_filtered <- polls %>% filter(candidate_name %in% c("Amy Klobuchar",
"Bernard Sanders",
"Elizabeth Warren",
"Joseph R. Biden Jr.",
"Michael Bloomberg",
"Pete Buttigieg")) %>%
select(candidate_name,
sample_size,
start_date,
party,
pct)
# compare the names of candidates of the two datasets
# identify differences
sort(unique(polls_filtered$candidate_name))
sort(unique(Endorsements$candidate_name))
# use dplyr to make them the same
polls_filtered <- polls_filtered %>%
# "Bernard Sanders" --> "Bernie Sanders"
mutate(candidate_name = replace(candidate_name,
candidate_name == "Bernard Sanders",
"Bernie Sanders" )) %>%
# "Joseph R. Biden Jr." --> "Joe Biden"
mutate(candidate_name = replace(candidate_name,
candidate_name == "Joseph R. Biden Jr.",
"Joe Biden"))
# Check to see if changes are made
sort(unique(polls_filtered$candidate_name))
sort(unique(Endorsements$candidate_name))
joined_df <- merge(polls_filtered, Endorsements,
by = "candidate_name")
unique(joined_df$candidate_name)
cnt_endorsement <- joined_df %>%
group_by(candidate_name) %>%
count() %>%
rename(endorsement_count = n)
cnt_endorsement
p <- ggplot(cnt_endorsement, aes(x = factor(candidate_name),
y = endorsement_count,
fill = cnt_endorsement$candidate_name,
label = cnt_endorsement$endorsement_count)) +
geom_bar(stat = "identity", width = 0.5) +
xlab("Candidate Name") +
ylab("Number of endorsement") +
scale_fill_discrete(name = "Candidates") +
geom_text(size = 3, position = position_stack(vjust = 0.9))
p
p + theme_dark()
p <- p + theme_classic() +
ggtitle("Candidate Endorsement Comparison") +
theme(axis.text.x = element_text(angle = 10, vjust = 0.5, hjust=0.5))
p
# save to file
# please see github repo
# ggsave("endorsement_plot.pdf", p)
# trump_tweets_url <- 'https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv'
tweets <- read_csv("trump_tweets.csv")
# modify in place
tweets <- tweets %>%
# create a new col date to store the dates
mutate(date = str_split_fixed(tweets$created_at, " ", 2)[,1]) %>%
# create a new col time to store the timestamps
mutate(time = str_split_fixed(tweets$created_at, " ", 2)[,2])
# convert to date
tweets$date <- as.Date(tweets$date, "%m/%d/%Y")
# find the range of dates:
# from "2014-01-01" to "2020-02-14"
max(tweets$date)
min(tweets$date)
original_tweets <- tweets %>%
# remove retweets
filter(is_retweet == FALSE)
original_tweets %>%
# top 5 most popular
top_n(n = 5, wt = favorite_count) %>%
arrange(desc(favorite_count)) %>%
select(text)
original_tweets %>%
# top 5 most retweeted
top_n(n = 5, wt = retweet_count) %>%
arrange(desc(retweet_count)) %>%
select(text)
Corpus <- VCorpus(VectorSource(original_tweets$text))
Corpus <- Corpus %>%
# remove numbers
tm_map(removeNumbers) %>%
# remove punctuation
tm_map(removePunctuation, ucp = TRUE) %>%
# remove whitespace
tm_map(stripWhitespace)
# convert to lower case
Corpus <- tm_map(Corpus, content_transformer(tolower))
# remove stop words
Corpus <- tm_map(Corpus, removeWords, stopwords("english"))
# tdm <- TermDocumentMatrix(Corpus)
# findFreqTerms(tdm, 1000, Inf)
# findMostFreqTerms(tdm, n = 1)
tdm <- TermDocumentMatrix(Corpus)
matrix <- as.matrix(tdm)
library(usethis)
usethis::edit_r_environ()
knitr::opts_chunk$set(echo = TRUE)
options(width = 80)
# Change eval=FALSE in the code block. Install packages as appropriate.
library(fivethirtyeight)
library(tidyverse)
library(dplyr)
library(readr)
library(tidytext)
library(tm)
library(lubridate)
library(wordcloud)
# trump_tweets_url <- 'https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv'
tweets <- read_csv("trump_tweets.csv")
# modify in place
tweets <- tweets %>%
# create a new col date to store the dates
mutate(date = str_split_fixed(tweets$created_at, " ", 2)[,1]) %>%
# create a new col time to store the timestamps
mutate(time = str_split_fixed(tweets$created_at, " ", 2)[,2])
# convert to date
tweets$date <- as.Date(tweets$date, "%m/%d/%Y")
# find the range of dates:
# from "2014-01-01" to "2020-02-14"
max(tweets$date)
min(tweets$date)
original_tweets <- tweets %>%
# remove retweets
filter(is_retweet == FALSE)
original_tweets %>%
# top 5 most popular
top_n(n = 5, wt = favorite_count) %>%
arrange(desc(favorite_count)) %>%
select(text)
original_tweets %>%
# top 5 most retweeted
top_n(n = 5, wt = retweet_count) %>%
arrange(desc(retweet_count)) %>%
select(text)
Corpus <- VCorpus(VectorSource(original_tweets$text))
Corpus <- Corpus %>%
# remove numbers
tm_map(removeNumbers) %>%
# remove punctuation
tm_map(removePunctuation, ucp = TRUE) %>%
# remove whitespace
tm_map(stripWhitespace)
# convert to lower case
Corpus <- tm_map(Corpus, content_transformer(tolower))
# remove stop words
Corpus <- tm_map(Corpus, removeWords, stopwords("english"))
# tdm <- TermDocumentMatrix(Corpus)
# findFreqTerms(tdm, 1000, Inf)
# findMostFreqTerms(tdm, n = 1)
tdm <- TermDocumentMatrix(Corpus)
matrix <- as.matrix(tdm)
# words <- sort(rowSums(matrix),decreasing=TRUE)
# df <- data.frame(word = names(words),freq=words)
tweets_words <-  original_tweets %>%
select(text) %>%
unnest_tokens(word, text)
words <- tweets_words %>% count(word, sort=TRUE)
# library(usethis)
# usethis::edit_r_environ()
words
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
View(df)
knitr::opts_chunk$set(echo = TRUE)
options(width = 80)
# Change eval=FALSE in the code block. Install packages as appropriate.
library(fivethirtyeight)
library(tidyverse)
library(dplyr)
library(readr)
library(tidytext)
library(tm)
library(lubridate)
library(wordcloud)
# resolve memory issue
# library(usethis)
# usethis::edit_r_environ()
# generate wordcloud
set.seed(12345) # for reproducibility
wordcloud(words = df$word, freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word[1,50], freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3.5,0.25))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(5,5))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,5))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=FALSE, rot.per=0.35,
# colors=brewer.pal(8, "Dark2"),
color='random-dark',
scale=c(3,1))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
wordcloud2(data=df$word[1:50], size=1.6, color='random-dark')
library(wordcloud2)
install.pacakges("wordcloud2")
install.packages("wordcloud2")
library(wordcloud2)
knitr::opts_chunk$set(echo = TRUE)
options(width = 80)
# Change eval=FALSE in the code block. Install packages as appropriate.
library(fivethirtyeight)
library(tidyverse)
library(dplyr)
library(readr)
library(tidytext)
library(tm)
library(lubridate)
library(wordcloud)
library(wordcloud2)
# resolve memory issue
# library(usethis)
# usethis::edit_r_environ()
wordcloud2(data=df$word[1:50], size=1.6, color='random-dark')
# generate term document matrix
tdm <- TermDocumentMatrix(Corpus)
matrix <- as.matrix(tdm)
words <- sort(rowSums(matrix), decreasing = T)
df <- data.frame(word = names(words), freq = words)
# generate wordcloud
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
wordcloud2(data=df$word[1:50], size=1.6, color='random-dark')
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
scale=c(3,1))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
# colors=brewer.pal(8, "Dark2"),
colorPalette = "Dark2",
scale=c(3,1))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(50, "Dark2"),
# colorPalette = "Dark2",
scale=c(3,1))
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(10, "Dark2"),
# colorPalette = "Dark2",
scale=c(3,1))
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(10, "Dark2"),
# colorPalette = "Dark2",
scale=c(3,1))
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(10, "Dark2"),
# colorPalette = "Dark2",
scale=c(3,1))
set.seed(12345) # for reproducibility
wordcloud(words = df$word[1:50], freq = df$freq, min.freq = 3,
max.words=200, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(10, "Dark2"),
# colorPalette = "Dark2",
scale=c(3,1))
